---
title: "FPL_Analysis_2223_modelling"
author: 
- "Tong LAN (24056082)"
- "Hanyu XUE (24070974)"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(warning = FALSE)
```

# Introduction

## Load libraries

```{r library, message=FALSE}
library(tidyverse)
library(knitr)
library(hrbrthemes)
library(RColorBrewer)
library(gridExtra)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(dendextend)
library(ROCR)
```

## Read Data

```{r read_data, message=FALSE}
path <- "./FPL_Dataset_2022-2023.csv"
fpl_raw_data <- read.csv(path)
```

# Data Preprocessing

## Initial Transform

```{r transform, results='hide'}
model_data <- fpl_raw_data %>%
  # discard some columns, which are not useful for our analysis
  # for example, names, teams, points, news and variable related to cost
  select(
    -c(
      "id",
      "team",
      "name",
      "now_cost",
      "transfers_out",
      "value_form",
      "value_season",
      "cost_change_start",
      "news_added",
      "cost_change_start_fall",
      "ep_next",
      "event_points",
      "web_name",
      "status",
      "news",
      "chance_of_playing_next_round",
      "dreamteam_count",
      "chance_of_playing_this_round",
      "points_per_game",
      "total_points",
      "in_dreamteam",
      "form",
      "ep_this",
      "transfers_in",
      "selected_by_percent",
      "bps",
      "bonus"
    )
  ) %>%
  select(-ends_with("rank")) %>%
  select(-ends_with("rank_type"))

str(model_data)
summary(model_data)

# remove raw data
rm(fpl_raw_data)
```

## Handle Missing Values

```{r missing_values}
# check missing values
sum(is.na(model_data))
# check which columns have missing values
missing_values_sum <- colSums(is.na(model_data) > 0)
missing_values_cols <- missing_values_sum[missing_values_sum > 0]
missing_values_cols
# convert missing values columns to categorical variables, True represent not missing and False represent missing
model_data <- model_data %>%
  mutate(
    corners_and_indirect_freekicks_order = ifelse(is.na(corners_and_indirect_freekicks_order), "Non-Taker", "Taker"),
    penalties_order = ifelse(is.na(penalties_order), "Non-Taker", "Taker"),
    direct_freekicks_order = ifelse(is.na(direct_freekicks_order), "Non-Taker", "Taker")
  )
# check missing values again
sum(is.na(model_data))
```

## Future Engineering

drop Position Column because it is highly correlated with the label column, like we just used it to create the label column.

Then, we should covert the label column to numerical values, 1 present offensive, 0 present defensive.

```{r transform_2, results='hide'}
model_data <- model_data %>%
  # drop highly correlated columns, if a variable has per 90 values, remain per 90 values instead of the origin ones because they are more useful for further analysis
  select(
    -c(
      "clean_sheets",
      "expected_assists",
      "starts",
      "expected_goals_conceded",
      "saves",
      "expected_goal_involvements",
      "expected_goals",
      "goals_conceded"
    )
  ) %>%
  # transform other performance variable to per 90 values
  mutate(assists_per_90 = assists / minutes * 90, .after = assists) %>% 
  mutate(goals_scored_per_90 = goals_scored / minutes * 90, .after = goals_scored) %>%
  mutate(red_cards_per_90 = red_cards / minutes * 90, .after = red_cards) %>%
  mutate(threat_per_90 = threat / minutes * 90, .after = threat) %>%
  mutate(influence_per_90 = influence / minutes * 90, .after = influence) %>%
  mutate(creativity_per_90 = creativity / minutes * 90, .after = creativity) %>%
  mutate(own_goals_per_90 = own_goals / minutes * 90, .after = own_goals) %>%
  mutate(yellow_cards_per_90 = yellow_cards / minutes * 90, .after = yellow_cards) %>%
  # drop the origin columns
  select(
    -c(
      "assists",
      "goals_scored",
      "red_cards",
      "threat",
      "influence",
      "creativity",
      "own_goals",
      "yellow_cards"
    )) %>% 
  # drop columns highly correlated with the some other columns
  select(
    -c(
      "penalties_missed",
      "penalties_saved",
      "ict_index"
    )
  )

str(model_data)
summary(model_data)
```

### Features that were removed

### Features that were included

```{r missing_values_2}
# count missing values
missing_values <- apply(is.na(model_data), 2, sum)
na_values <- which(missing_values > 0)
na_values
# if the actual value and expected value are both 0, then the actual value of 90 and expected value of 90 will result in NaN
# if the expected 90 values are NaN, it means that the player did not play a single minute
model_data <- model_data %>%
  mutate(
    assists_per_90 = ifelse(is.na(assists_per_90), 0, assists_per_90),
    goals_scored_per_90 = ifelse(is.na(goals_scored_per_90), 0, goals_scored_per_90),
    red_cards_per_90 = ifelse(is.na(red_cards_per_90), 0, red_cards_per_90),
    threat_per_90 = ifelse(is.na(threat_per_90), 0, threat_per_90),
    influence_per_90 = ifelse(is.na(influence_per_90), 0, influence_per_90),
    creativity_per_90 = ifelse(is.na(creativity_per_90), 0, creativity_per_90),
    own_goals_per_90 = ifelse(is.na(own_goals_per_90), 0, own_goals_per_90),
    yellow_cards_per_90 = ifelse(is.na(yellow_cards_per_90), 0, yellow_cards_per_90)
  )

# look at the missing values again, they have been cleaned
missing_values <- apply(is.na(model_data), 2, sum)
missing_values
```

convert categorical column to numerical values. convert logical columns to numerical values.

<!-- ```{r covert_to_numerical} -->

<!-- train_data <- train_data %>% -->

<!--   # convert categorical column to numerical values -->

<!--   mutate( -->

<!--     position = ifelse(position == "GKP", 1, -->

<!--                       ifelse(position == "DEF", 2, -->

<!--                              ifelse(position == "MID", 3, 4))) -->

<!--   ) %>% -->

<!--   # convert logical columns to numerical values -->

<!--   mutate( -->

<!--     penalties_order = ifelse(penalties_order == TRUE, 1, 0), -->

<!--     direct_freekicks_order = ifelse(direct_freekicks_order == TRUE, 1, 0), -->

<!--     corners_and_indirect_freekicks_order = ifelse(corners_and_indirect_freekicks_order == TRUE, 1, 0) -->

<!--     ) %>%  -->

<!--   rename( -->

<!--     penalties_taker = "penalties_order", -->

<!--     direct_freekicks_taker = "direct_freekicks_order", -->

<!--     corners_and_indirect_freekicks_taker = "corners_and_indirect_freekicks_order" -->

<!--   ) -->

<!-- ``` -->

## Target Value

add a target column

```{r target}
model_data <- model_data %>%
  # create target column, 1 represents offensive player, 0 represents defensive player
  mutate(player_type = ifelse(position == 'GKP' |
                                position == 'DEF', "Defensive", "Offensive"),
         .before = position) %>%
  select(-position)

knitr::kable(model_data[1:5, 1:5], caption =  "First 5 rows and first 5 conlumns of data")
```

### plot target value
```{r target_value_barplot}
# plot target value
model_data %>% 
  ggplot(aes(x = player_type, fill = player_type)) +
  geom_bar(alpha = 0.8, width = 0.8) +
  geom_label(stat = "count", aes(label = ..count..), show.legend = F) +
  theme_ipsum() +
  scale_fill_brewer(palette = "Set1")
```

```{r target_value_donut}
model_data %>%
  mutate(player_type = ifelse(player_type == "Defensive", 0, 1)) %>% 
  group_by(player_type) %>%
  summarise(count = n()) %>%
  mutate(
    percentage = count / sum(count),
    ymax = cumsum(percentage),
    ymin = c(0, head(ymax, n = -1)),
    labelPosition = (ymax + ymin) / 2,
    label = paste(ifelse(player_type == 0, 'Defensive' , 'Offensive'),
                  "\n",
                  round(percentage * 100, 2),
                  "%",
                  sep = "")
  ) %>%
  ggplot(aes(
    ymax = ymax,
    ymin = ymin,
    xmax = 4,
    xmin = 3,
    fill = as.factor(player_type)
  )) +
  geom_rect() +
  coord_polar(theta = "y") +
  geom_label(x = 3.5,
             aes(y = labelPosition, label = label),
             size = 4) +
  scale_fill_brewer(palette = 4) +
  scale_color_brewer(palette = 3) +
  xlim(c(2, 4)) +
  theme_void() +
  theme(legend.position = "none")
```



## Split data into 2 sets

```{r split data}
#do a 90/10 split to form the training and test sets.
set.seed(500)
fortrain <- runif(nrow(model_data)) < 0.9
train_data <- model_data[fortrain,]
test_data <- model_data[!fortrain,]

#prepare the data for modelling
outCol <- names(train_data)[-1]
outCome <- 'player_type'

#divid data into numerical and categorical
vars <- setdiff(outCol, c('player_type'))
catVars <- vars[sapply(train_data[, vars], class) %in%
c('factor', 'character')]
numericVars <- vars[sapply(train_data[, vars], class) %in%
c('numeric', 'integer')]
```




# Classification

## Binary Classification Problem

offensive and defensive

## Single Variable
- Single variable predictions model: feature
```{r Single variable predictions}
mkPredC <- function(outCol,varCol,appCol, pos=pos.label) {
  pPos <- sum(outCol == pos) / length(outCol)
  naTab <- table(as.factor(outCol[is.na(varCol)]))
  pPosWna <- (naTab / sum(naTab))[pos]
  vTab <- table(as.factor(outCol),varCol)
  pPosWv <- (vTab[pos,]+1.0e-3 * pPos) / (colSums(vTab)+1.0e-3)
  pred <- pPosWv[appCol]
  pred[is.na(appCol)] <- pPosWna
  pred[is.na(pred)] <- pPos
  pred
}
```


## Null Model and Single Variable Model Evaluation


#### LogLikelyhood
```{r loglikelyhood}


```

## Feature Selection

Feature selection is typically carried out to identify the most relevant features from a larger set of available features. This process helps improve the performance of the classification model by reducing dimensionality, eliminating irrelevant or redundant features, and enhancing interpretability.



### Feature Selection Methods

Since our dataset contains both categorical and numerical features, we cannot use simple filter methods such as Pearson Correlation or Chi-Square Test to select features. Because they work only in categorical variables and numerical variables respectively. Instead, we will use the following methods to select features.

> A key part of building many variable models is selecting what variables to use. Each
variable we use represents a chance of explaining more of the outcome variation (a
chance of building a better model), but also represents a possible source of noise and
overfitting. To control this effect, we often preselect which subset of variables weâ€™ll use
to fit.

> Practical Data Science With R

#### Recursive Feature Elimination - Wrapped Methods

```{r RFE}

features <- train_data %>% 
  select(-c("player_type"))
target <- train_data$player_type

# Specify the number of desired features to select
num_features <- 3

# Create the RFE control object
ctrl <- rfeControl(
  functions = rfFuncs,  # Use decision tree as the learning algorithm
  method = "cv",  # Cross-validation method
  number = 5,  # Number of folds for cross-validation
  verbose = FALSE
)

# Perform feature selection using RFE
rfe_result <- rfe(features, target, sizes = num_features, rfeControl = ctrl)

# Get the selected features
selected_features <- rfe_result$optVariables
```

## Single Variable

### For Categorical

- Create a function for single variable predictions

```{r Single variable predictions}
pos <- '1'
outCol <- names(train_data)[-1]
varCol <- 
mkPredC <- function(outCol,varCol,appCol, pos=pos.label) {
  pPos <- sum(outCol == pos) / length(outCol)
  naTab <- table(as.factor(outCol[is.na(varCol)]))
  pPosWna <- (naTab / sum(naTab))[pos]
  vTab <- table(as.factor(outCol),varCol)
  pPosWv <- (vTab[pos,]+1.0e-3 * pPos) / (colSums(vTab)+1.0e-3)
  pred <- pPosWv[appCol]
  pred[is.na(appCol)] <- pPosWna
  pred[is.na(pred)] <- pPos
  pred
}
```

```{r}
# call the predict function for the candidate columns
for(v in catVars) {
  pi <- paste('pred', v, sep='')
  dTrain[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dTrain[,v])
  dCal[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dCal[,v])
  dTest[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dTest[,v])
}
```

- Evaluate the performance of each single variable model by AUC

```{r}
calcAUC <- function(predcol, outcol) {
  perf <- performance(prediction(predcol, outcol == pos), 'auc')
  as.numeric(perf@y.values)
}
```

```{r}
for(v in catVars) {
  pi <- paste('pred', v, sep = '')
  aucTrain <- calcAUC(dTrain[, pi], dTrain[, outcome])
  if (aucTrain >= 0.8) {
    aucCal <- calcAUC(dCal[, pi], dCal[, outcome])
    print(sprintf(
      "%s: trainAUC: %4.3f; calibrationAUC: %4.3f",
      pi,
      aucTrain,
      aucCal
    ))
  }
}
```

(type later: explanation for result here) 
### For Numerical
- Create a function for single variable predictions
```{r}
mkPredN <- function(outCol, varCol, appCol) {
# compute the cuts
cuts <- unique(
quantile(varCol, probs=seq(0, 1, 0.1), na.rm=T))
# discretize the numerical columns
varC <- cut(varCol,cuts)
appC <- cut(appCol,cuts)
mkPredC(outCol,varC,appC)
}
```
- Evaluate the performance of each single variable model by AUC

## Multiple Variables

### Decision Tree

### Random Forest

### XGBoost

## Module Evaluation

# Cluster
